% !TeX spellcheck = pl_PL
\chapter{Optymalizacja procesu rekrutacji w~branży IT z~wykorzystaniem uczenia maszynowego}\label{ch:analysis}
\section{Metody badawcze}\label{sec:analysis-method}
Biorąc pod uwagę rosnące zapotrzebowanie na usługi informatyczne, deficyt wykwalifikowanych pracowników \cite{daxx-2021} oraz wysoki koszt rekrutacji nowych pracowników \cite{hairing-dev-2021} istotne jest poszukiwanie sposobów na zwiększenie retencji pracowników IT.
Badania będące przedmiotem niniejszej pracy mają na celu analizę cech skorelowanych z~zadowoleniem pracowników branży IT i~z ich chęcią do zmiany pracy.
% Badane cechy zostaną podzielone na 4 kategorie:
% \begin{enumerate}
%     \item profil firmy (rozmiar firmy),
%     \item organizacja firmy (rozmiar zespołów, metodyka zarządzania projektem),
%     \item profil pracownika (wiek, płeć, staż pracy, wykształcenie),
%     \item preferencje pracownika (technologia, benefity pracownicze).
%     \end{enumerate}
%
% Powyższe kategorie dzielą cechy firmy i~pracownika na 2 zasadnicze typy:
% \begin{enumerate}
%     \item cechy profilowe~- profil firmy i~profil pracownika,
%     \item cechy zmienne~- organizacja firmy i~preferencje pracownika.
%     \end{enumerate}
%
% Cechy profilowe mogą być uznawane za niezmienne w~kontekście prowadzonego badania, gdyż ich zmiana może całkowicie zmienić istotne cechy podmiotu
% (na przykład w~przypadku liczby pracowników zmiana może dotyczyć przekształcenia małej firmy w~międzynarodową korporację, a~w przypadku wieku pracownika zmiany z~młodej osoby w~osobę w~wieku przedemerytalnym~- w~obu przypadkach oczekiwania firmy wobec pracowników i~vice versa będą inne).
% Natomiast cechy zmienne mogą być zmieniane tak aby dostosować je do bieżących potrzeb.

Celem badania jest określenie czy i~jeśli tak to jakie cechy firmy i~pracownika mogą mieć istotny wpływ na zadowolenie pracownika
oraz czy można wyszczególnić cechy organizacyjne firmy, których modyfikacja mogłaby pozwolić na zwiększenie zadowolenia pracowników.
Określenie takich cech miałoby szczególne znaczenie już na etapie rekrutacji, gdyż mogłoby umożliwić selekcjonowanie kandydatów o~profilu "kompatybilnym" z~profilem firmy.


Badania zostaną przeprowadzone w~oparciu o~ankietę developerską StackOverflow \cite{so-survey-info}.
Ankieta ta jest przeprowadzana corocznie od 2011 roku, jednak popularność zyskała dopiero w~2016 roku, kiedy to liczba respondentów biorących udział w~badaniu przekroczyła 50 tysięcy.
W latach 2016-2022 liczba respondentów utrzymywała się na poziomie od 50 do 100 tysięcy.
Odpowiedzi w~ankiecie udzielali specjaliści z~całego świata reprezentując różne grupy wiekowe i~kulturowe.
Tak wysoka liczba odpowiedzi i~różnorodność respondentów może pozwolić na przeprowadzenie badań ilościowych i~umożliwić próbę generalizacji wniosków na całą branżę IT.


Do analizy danych zostaną wykorzystane metody uczenia maszynowego, a~w szczególności regresja z~wykorzystaniem regresora XGBoost opartego na algorytmie wzmocnienia gradientowego.
Zdecydowano się na modelowanie problemu jako regresji, a~nie klasyfikacji, gdyż zadowolenie pracowników oraz chęć zmiany pracy można przedstawić na skali liczbowej.
Punnoose i~Ajit \cite{punnoose-2016} przeprowadzili badania związane ze skutecznością przewidywania retencji pracowników w~firmie z~wykorzystaniem uczenia maszynowego.
Klasyfikator XGBoost osiągnął aż 86\% skuteczności klasyfikacji co stanowiło ponad 50\% lepszy wynik niż pozostałe testowane metody klasyfikacji tradycyjnie używane podczas badania problemu fluktuacji i~retencji pracowników.
Do celów badań będących przedmiotem niniejszej pracy implementacja algorytmu regresji i klasyfikacji zostanie przygotowana w języku Python.


\section{Wstępne przetworzenie danych}\label{sec:analysis:preprocessing}
Do przeprowadzenia badania wybrano ankiety deweloperskie StackOverflow z~lat 2017, 2018, 2019 (dostępne do pobrania pod adresem \url{https://insights.stackoverflow.com/survey}) ze względu na to, że są to 3 najnowsze edycje ankiety w~których zadano pytania o~następujące 2 aspekty:
\begin{enumerate}
    \item ocena zadowolenia z~obecnie wykonywanej pracy w~10 stopniowej skali,
    \item status poszukiwania pracy w~3 stopniowej skali.
    \end{enumerate}

Powyższe aspekty zostaną wykorzystane w badaniu jako zmienne zależne, czyli zmienne których wartość chcemy wyznaczać wykorzystując model predykcji.
Dla badań z wykorzystaniem algorytmu regresji zmienne zależne pozostawiono w oryginalnej skali,
natomiast dla algorytmu klasyfikacji odpowiedzi sprowadzono do klasyfikacji binarnej przy następujących założeniach:
\begin{enumerate}
    \item pracownik jest zadowolony z pracy jeśli ocenił poziom zadowolenia na 5 lub więcej,
    \item pracownik ma status osoby poszukującej jeśli szuka pracy aktywnie lub jest otwarty na atrakcyjne oferty pracy.
    \end{enumerate}

W celu przygotowania danych do badania konieczne było oczyszczenie i~znormalizowanie danych. Proces ten został przeprowadzony w~następujący sposób:
\begin{enumerate}
    \item Usunięto pytania, które nie mają istotnego wpływu na badany problem (na przykład pytanie dotyczące preferencji związanej z~wymawianiem słowa "GIF").
    \item Uwspólniono nazwy etykiet dotyczących tych samych pytań w~kolejnych edycjach ankiety.
    \item Usunięto odpowiedzi respondentów, którzy nie mają doświadczenia zawodowego lub nie udzielili odpowiedzi na pytania dotyczące zadowolenia z~pracy i~statusu poszukiwania pracy.
    \item Dla pytań z~odpowiedzami w~skali Likerta (typu od "bardzo się nie zgadzam" do "bardzo się zgadzam") zastosowano przekształcenie na skalę liczbową.
    \item Dla pytań z~odpowiedziami reprezentowanymi przez kategorie, które można przedstawić w~skali (na przykład edukacja) zastosowano przekształcenie na skalę liczbową.
    \item Dla pytań wielokrotnego wyboru oraz dla pytań z~odpowiedziami reprezentowanymi przez kategorie, których nie można przedstawić w~skali (na przykład technologie) potraktowano każdą kategorię jak osobne pytanie i~zastosowano kodowanie binarne (0~- niewystępuje i~1~- występuje).
    \item Kraj pochodzenia respondenta po zastąpieniu kodowaniem binarnym daje w~rezultacie macierz rzadką z~zaledwie 1 elementem niezerowym. Z~tego powodu kraj pochodzenia respondenta zastąpiono wartością wskaźnika rozwoju społecznego HDI (ang. Human Development Index) \cite{hdi} odpowiednią dla danego kraju i~roku badania.
    \item Wynagrodzenie respondentów przeliczono na wartość w~dolarach amerykańskich (USD) według kursu z~1 dnia roku w~którym przeprowadzono badanie.
    \item W~pytaniach na które respondent nie udzielił odpowiedzi, wartości uzupełniono średnią wartością z~pozostałych odpowiedzi, żeby wartości te nie wpływały negatywnie na działanie algorytmu regresji.
    \item Na koniec wszystkie wartości przeskalowano aby otrzymać wartości z~przedziału 0~- 1.
    \end{enumerate}

\section{Selekcja cech z~wykorzystaniem uczenia maszynowego}\label{sec:analysis:feature-selection-xgb}

Do trenowania modelu uczenia maszynowego wykorzystano algorytm przedstawiony na listingu \ref{listing:xgb}.


\noindent\begin{minipage}{\textwidth}
    \begin{lstlisting}[caption={Algorytm uczenia modelu regresji}, label={listing:xgb}]
    \end{lstlisting}
    \hspace{.075\textwidth}\begin{minipage}{.85\textwidth}
        \begin{minted}{python}
import xgboost as xgb
import pandas as pd
import matplotlib.pyplot as plt
import math
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.feature_selection import SelectFromModel

def fit_model(data, dependent_variable, name):
    def fit_estimator(x_set, y_set):
        estimator = xgb.XGBRegressor(**estimator_params, eval_metric='rmsle')
        estimator.fit(x_set, y_set)
        return estimator

    x = data.drop(regression_dependent_variables + class_dependent_variables, axis=1)
    y = data[dependent_variable]

    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y)

    selection = SelectFromModel(fit_estimator(x_train, y_train), threshold=.015, prefit=True)

    selection_estimator = fit_estimator(selection.transform(x_train), y_train)
    preds = selection_estimator.predict(selection.transform(x_test))
    print("RMSE: %.2f" % math.sqrt(abs(mean_squared_error(y_test, preds))))
    print("R2: %.2f" % r2_score(y_test, preds))

    xgb.plot_importance(selection_estimator, max_num_features=10)
    plt.tight_layout()
    plt.savefig(f'data/feat_importance_{name}.png')
        \end{minted}
    \end{minipage}

    \raggedright\source{\ownwork}
    \vspace{0.75cm}
\end{minipage}

Hiperparametry estymatora wyznaczono w~oparciu o~projekt Harathi \cite{harathi-2018} oraz z~wykorzystaniem narzędzia GridSearchCV.
Dodatkowo skorzystano z~metody histogramowej do budowania drzewa decyzyjnego w~celu skrócenia czasu uczenia modelu \cite{golarnyk-2021}.
Wyznaczone parametry przedstawiono na listingu \ref{listing:estimator_params}.


\noindent\begin{minipage}{\textwidth}
             \begin{lstlisting}[caption={Parametry estmatora}, label={listing:estimator_params}]
             \end{lstlisting}
             \hspace{.075\textwidth}\begin{minipage}{.85\textwidth}
                                        \begin{minted}{python}
estimator_params = {
    'tree_method': "hist",
    'single_precision_histogram': True,
    'n_jobs': -1,
    'n_estimators': 1500,
    'importance_type': 'weight',
    'use_label_encoder': False,
    'booster': 'gbtree',
    'scale_pos_weight': 1,
    'reg_alpha': 5,
    'colsample_bytree': .8,
    'learning_rate': .1,
    'min_child_weight': 7,
    'subsample': .5,
    'max_depth': 6,
    'gamma': 0.1,
    'reg_lambda': 1
}
        \end{minted}
     \end{minipage}

     \raggedright\source{\ownwork}
     \vspace{0.75cm}
\end{minipage}

Do sprawdzenia skuteczności predykcji modelu regresji wykorzystano następujące miary:
\begin{itemize}
    \item Pierwiastek logarytmu błędu średniokwadratowego RMSLE (ang. Root Mean Squared Logarytmic Error)~- pokazuje jak bardzo predykcja jest oddalona od oczekiwanej wartości. Im niższa wartość tym lepiej.
    \item Współczynnik determinacji R2~- pokazuje w~jakim stopniu predykcja jest dopasowana do oczekiwanej wartości. Im wyższa wartość tym lepiej.
    \end{itemize}

Celem modelu jest maksymalizacja R2 i~minimalizacja RMSLE. Dobrze dopasowany model powinien mieć wartość R2 na poziomie powyżej 70\% \cite{r2-good-value}, jednak nawet przy niskiej wartości R2 model może być użyteczny jeżeli RMSLE ma wartość poniżej 10\% \cite{r2-vs-rmse}.
Natomiast przy akceptowalnym poziomie współczynnika R2, model może być użyteczny jeśli RMSLE nie przekracza 50\% \cite{rmse-good-value}.
Ma to szczególne znaczenie w~przypadku badań prowadzonych w~obszarze nauk o~społeczeństwie, gdyż nawet model nie oferujący bardo wysokiej skuteczności predykcji może pozwolić na pogłębienie wglądu w~kwestię zachowań społecznych.

Sprawdzenie skuteczności modelu klasyfikacji oparte jest na znacznie prostszym mechanizmie wyznaczania procentowej dokładności predykcji (ang. accuracy).
\todo{precission, recall}

Selekcję pytań najsilniej wpływających na predykcję wykonano z wykorzystaniem metody SHAP (ang. SHapley Additive exPlanations)
\todo{https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137}
\todo{https://medium.com/dataman-in-ai/explain-your-model-with-the-shap-values-bc36aac4de3d}

\section{Prezentacja wyników}\label{sec:analysis:important-features}
%\bargraph{{AssessJobIndustry}, {AssessJobExp}, {AssessJobLeaders}, {AssessJobProfDevel}, {AssessJobDiversity}, {AssessJobFinances}, {StackOverflowCompanyPage}, {StackOverflowMetaChat}, {ImportantBenefits\_Vacation/day}, {ImportantBenefits\_Remote optio}}{(0.27,{AssessJobIndustry}) (2.60,{AssessJobExp}) (0.15,{AssessJobLeaders}) (1.34,{AssessJobProfDevel}) (3.01,{AssessJobDiversity}) (0.72,{AssessJobFinances}) (0.67,{StackOverflowCompanyPage}) (0.51,{StackOverflowMetaChat}) (0.47,{ImportantBenefits\_Vacation/day}) (0.33,{ImportantBenefits\_Remote optio})}{feat\_importance\_2017\_JobSeekingStatus}{feat\_importance\_2017\_JobSeekingStatus}{10cm}

\imagescale{0.75}{../code/feat_importance/feat_importance_2017_JobSatisfaction.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2017}{result1}

\imagescale{0.75}{../code/feat_importance/feat_importance_2017_JobSatisfaction_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2017}{result2}

\imagescale{0.75}{../code/feat_importance/feat_importance_2017_JobSeekingStatus.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2017}{result3}

\imagescale{0.75}{../code/feat_importance/feat_importance_2017_JobSeekingStatus_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2017}{result4}

\imagescale{0.75}{../code/feat_importance/feat_importance_2018_JobSatisfaction.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2018}{result11}

\imagescale{0.75}{../code/feat_importance/feat_importance_2018_JobSatisfaction_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2018}{result12}

\imagescale{0.75}{../code/feat_importance/feat_importance_2018_JobSeekingStatus.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2018}{result13}

\imagescale{0.75}{../code/feat_importance/feat_importance_2018_JobSeekingStatus_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2018}{result14}

\imagescale{0.75}{../code/feat_importance/feat_importance_2019_JobSatisfaction.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2019}{result21}

\imagescale{0.75}{../code/feat_importance/feat_importance_2019_JobSatisfaction_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSatisfaction dla ankiety StackOverflow z roku 2019}{result22}

\imagescale{0.75}{../code/feat_importance/feat_importance_2019_JobSeekingStatus.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu regresji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2019}{result23}

\imagescale{0.75}{../code/feat_importance/feat_importance_2019_JobSeekingStatus_class.png}{Średnia siła wpływu 10 pytań najsilniej wpływających na predykcję w modelu klasyfikacji dla zmiennej zależnej JobSeekingStatus dla ankiety StackOverflow z roku 2019}{result24}

\todo{}
\section{Wnioski i~analiza możliwości praktycznego zastosowania zbudowanego modelu predykcji}\label{sec:analysis:model-fitness}
\todo{Analiza skuteczności (dopasowania) modelu}

\thispagestyle{normal}
